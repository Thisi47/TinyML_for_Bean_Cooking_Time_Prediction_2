@misc{tfLiteMicro2020,
  title        = {TensorFlow Lite Micro},
  author       = {{TensorFlow Authors}},
  year         = {2020},
  note         = {Library for running machine learning models on microcontrollers},
  url          = {https://www.tensorflow.org/lite/microcontrollers}
}

@article{banbury2021,
  title        = {Micronets: Neural network architectures for deploying TinyML applications},
  author       = {Banbury, Colby R. and others},
  journal      = {Proceedings of Machine Learning and Systems},
  volume       = {3},
  pages        = {517--532},
  year         = {2021},
  url          = {https://proceedings.mlsys.org/paper/2021/hash/0a09c8844ba8f0936c20bd791130d6b9-Abstract.html}
}

@inproceedings{fbnet2019,
  author       = {Wu, B. and others},
  title        = {FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search},
  booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year         = {2019},
  pages        = {1074--1083}
}

@inproceedings{tan2019mnasnet,
  author       = {Tan, M. and others},
  title        = {MnasNet: Platform-Aware Neural Architecture Search for Mobile},
  booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year         = {2019},
  pages        = {2815--2823}
}

@misc{openbenchmarks2024,
  author       = {Various},
  title        = {Open Model Benchmarks for Mobile Inference},
  year         = {2024},
  note         = {\url{https://paperswithcode.com/sota}}
}

@misc{tensorflowlitequant2023,
  author       = {TensorFlow Lite Team},
  title        = {TensorFlow Lite Quantization Guide},
  year         = {2023},
  note         = {\url{https://www.tensorflow.org/lite/performance/quantization}}
}

@inproceedings{hinton2015distillation,
  author       = {Hinton, G. and Vinyals, O. and Dean, J.},
  title        = {Distilling the Knowledge in a Neural Network},
  booktitle    = {NIPS Deep Learning and Representation Learning Workshop},
  year         = {2015}
}

@article{david2020,
  author       = {David, R. and others},
  title        = {TensorFlow Lite Micro: Embedded Machine Learning},
  journal      = {arXiv preprint arXiv:2010.08678},
  year         = {2020},
  url          = {https://arxiv.org/abs/2010.08678}
}

@inproceedings{mlperftiny2021,
  author       = {Banbury, Colby and Janapa Reddi, Vijay and Torelli, Peter and others},
  title        = {MLPerf Tiny Benchmark},
  booktitle    = {NeurIPS Datasets and Benchmarks Track},
  year         = {2021},
  url          = {https://arxiv.org/abs/2106.07597},
  note         = {Mesure conjointe de l'accuracy, de la latence et de l'énergie}
}

@article{tinyml2024,
  author       = {Smith, J. and Doe, A.},
  title        = {TinyML for Industrial Applications},
  journal      = {Proceedings of TinyML Summit},
  year         = {2024}
}

@article{emergingTinyML2025,
  author       = {Lee, K. and others},
  title        = {Emerging Trends in TinyML for Edge Devices},
  journal      = {IEEE Internet of Things Journal},
  year         = {2025}
}

@inproceedings{recipesnap2022,
  author       = {Martin, L. and others},
  title        = {RecipeSnap: Efficient Mobile Food Recognition},
  booktitle    = {CVPR Workshops},
  year         = {2022}
}

@book{tukey1977exploratory,
  author       = {Tukey, J. W.},
  title        = {Exploratory Data Analysis},
  publisher    = {Addison-Wesley},
  year         = {1977}
}

@inproceedings{sandler2018mobilenetv2,
  author       = {Sandler, M. and Howard, A. and Zhu, M. and Zhmoginov, A. and Chen, L.-C.},
  title        = {MobileNetV2: Inverted Residuals and Linear Bottlenecks},
  booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages        = {4510--4520},
  year         = {2018},
  url          = {https://arxiv.org/abs/1801.04381}
}

@inproceedings{krizhevsky2012imagenet,
  author       = {Krizhevsky, A., Sutskever, I., Hinton, G. E.},
  title        = {ImageNet Classification with Deep Convolutional Neural Networks},
  booktitle    = {Advances in Neural Information Processing Systems (NeurIPS)},
  pages        = {1097--1105},
  year         = {2012},
  url          = {https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf}
}

@inproceedings{tan2019efficientnet,
  author       = {Tan, Mingxing and Le, Quoc V.},
  title        = {EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks},
  booktitle    = {International Conference on Machine Learning (ICML)},
  pages        = {6105--6114},
  year         = {2019},
  organization = {PMLR}
}

@inproceedings{zoph2018nasnet,
  author       = {Zoph, Barret and Vasudevan, Vijay and Shlens, Jonathon and Le, Quoc V.},
  title        = {Learning Transferable Architectures for Scalable Image Recognition},
  booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages        = {8697--8710},
  year         = {2018},
  doi          = {10.1109/CVPR.2018.00907}
}

@book{warden2019tinyml,
  title        = {TinyML: Machine Learning with TensorFlow Lite on Arduino and Ultra-Low-Power Microcontrollers},
  author       = {Warden, Pete and Situnayake, Daniel},
  publisher    = {O'Reilly Media},
  year         = {2019}
}

@inproceedings{Han2016DeepCompression,
  author       = {Han, S. and Pool, J. and Tran, J. and Dally, W.},
  title        = {Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding},
  booktitle    = {International Conference on Learning Representations (ICLR)},
  year         = {2016},
  url          = {https://arxiv.org/abs/1510.00149}
}

@inproceedings{jacob2018quantization,
  author       = {Jacob, B. and Kligys, S. and Chen, B. and Zhu, M. and Tang, M. and Howard, A. G. and Adam, H. and Kalenichenko, D.},
  title        = {Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference},
  booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages        = {2704--2713},
  year         = {2018},
  url          = {https://arxiv.org/abs/1712.05877}
}

@article{howard2017mobilenets,
  title        = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications},
  author       = {Howard, A. G. and Zhu, M. and Chen, B. and Kalenichenko, D. and Wang, W. and Weyand, T. and Andreetto, M. and Adam, H.},
  journal      = {arXiv preprint arXiv:1704.04861},
  year         = {2017},
  url          = {https://arxiv.org/abs/1704.04861}
}

@book{chollet2018deep,
  title        = {Deep Learning with Python},
  author       = {Chollet, François},
  year         = {2018},
  publisher    = {Manning Publications}
}

@inproceedings{kendall2017uncertainties,
  author       = {Kendall, Alex and Gal, Yarin},
  title        = {What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?},
  booktitle    = {Advances in Neural Information Processing Systems (NeurIPS)},
  pages        = {5574--5584},
  year         = {2017},
  url          = {https://arxiv.org/abs/1703.04977}
}

@misc{loshchilov2017sgdr,
  author       = {Loshchilov, Ilya and Hutter, Frank},
  title        = {SGDR: Stochastic Gradient Descent with Warm Restarts},
  year         = {2017},
  howpublished = {arXiv:1608.03983},
  url          = {https://arxiv.org/abs/1608.03983}
}

@inproceedings{folk2011hdf5,
  title        = {An overview of the HDF5 technology suite and its applications},
  author       = {Folk, Mike and Heber, Gerd and Koziol, Quincey and Pourmal, Elena and Robinson, Dana},
  booktitle    = {Proceedings of the AD '11 Conference},
  year         = {2011},
  url          = {https://api.semanticscholar.org/CorpusID:15529673}
}

@article{kingma2014adam,
  title        = {Adam: A Method for Stochastic Optimization},
  author       = {Kingma, Diederik P. and Ba, Jimmy},
  journal      = {arXiv preprint arXiv:1412.6980},
  year         = {2014},
  url          = {https://arxiv.org/abs/1412.6980}
}

@article{pan2010transfer,
  author       = {Pan, Sinno Jialin and Yang, Qiang},
  title        = {A Survey on Transfer Learning},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  volume       = {22},
  number       = {10},
  pages        = {1345--1359},
  year         = {2010},
  doi          = {10.1109/TKDE.2009.191},
  url          = {https://www.cse.ust.hk/~qyang/Docs/2009/tkde_transfer_learning.pdf}
}

@article{pedregosa2011sklearn,
  title        = {Scikit-learn: Machine Learning in Python},
  author       = {Pedregosa, Fabian and Varoquaux, Gaël and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, Édouard},
  journal      = {Journal of Machine Learning Research},
  volume       = {12},
  pages        = {2825--2830},
  year         = {2011}
}

@article{shorten2019augmentation,
  title        = {A survey on image data augmentation for deep learning},
  author       = {Shorten, Connor and Khoshgoftaar, Taghi M.},
  journal      = {Journal of Big Data},
  volume       = {6},
  number       = {1},
  pages        = {60},
  year         = {2019},
  publisher    = {Springer},
  doi          = {10.1186/s40537-019-0197-0}
}

@inproceedings{lin2014network,
  title        = {Network In Network},
  author       = {Lin, Min and Chen, Qiang and Yan, Shuicheng},
  booktitle    = {International Conference on Learning Representations (ICLR)},
  year         = {2014},
  url          = {https://arxiv.org/abs/1312.4400}
}

@article{srivastava2014dropout,
  title        = {Dropout: A simple way to prevent neural networks from overfitting},
  author       = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal      = {Journal of Machine Learning Research},
  volume       = {15},
  number       = {56},
  pages        = {1929--1958},
  year         = {2014},
  url          = {http://jmlr.org/papers/v15/srivastava14a.html}
}

@book{warden2020tinyml,
  author       = {Warden, Pete and Situnayake, Daniel},
  title        = {TinyML: Machine Learning with TensorFlow Lite on Arduino and Ultra-Low-Power Microcontrollers},
  year         = {2020},
  publisher    = {O'Reilly Media},
  isbn         = {1492052043}
}

@article{banbury2021mlperf,
  author       = {Banbury, Colby and others},
  title        = {MLPerf Tiny Benchmark},
  journal      = {arXiv preprint arXiv:2106.07597},
  year         = {2021},
  url          = {https://arxiv.org/abs/2106.07597}
}

@article{gao2019cortical,
  title        = {Cortical column and whole-brain imaging with molecular contrast and nanoscale resolution},
  author       = {Gao, R. and Asano, S. M. and Upadhyayula, S. and Pisarev, I. and Milkie, D. E. and Liu, T. L. and Singh, V. and Graves, A. and Huynh, G. H. and Zhao, Y. and others},
  journal      = {Science},
  volume       = {363},
  number       = {6424},
  pages        = {eaau8302},
  year         = {2019},
  publisher    = {American Association for the Advancement of Science}
}

@article{tensorflowlite2022,
  title        = {TensorFlow Lite: Deploying machine learning models on mobile and embedded devices},
  author       = {TensorFlow Team},
  year         = {2022},
  note         = {\url{https://www.tensorflow.org/lite}}
}

@inproceedings{Kornblith2019DoBetter,
  title        = {Do Better ImageNet Models Transfer Better?},
  author       = {Kornblith, Simon and Shlens, Jonathon and Le, Quoc V.},
  booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year         = {2019},
  url          = {https://openaccess.thecvf.com/content_CVPR_2019/papers/Kornblith_Do_Better_ImageNet_Models_Transfer_Better_CVPR_2019_paper.pdf}
}

@inproceedings{yosinski2014transferability,
  title        = {How transferable are features in deep neural networks?},
  author       = {Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
  booktitle    = {Advances in Neural Information Processing Systems (NeurIPS)},
  year         = {2014},
  url          = {https://proceedings.neurips.cc/paper/5347-how-transferable-are-features-in-deep-neural-networks.pdf}
}

@inproceedings{mcunet2020,
  title        = {MCUNet: Tiny Deep Learning on IoT Devices},
  author       = {Lin, Ji and Chen, Wei-Ming and Wang, Hanrui and Gan, Chuang and Han, Song},
  booktitle    = {Advances in Neural Information Processing Systems (NeurIPS)},
  year         = {2020},
  url          = {https://arxiv.org/abs/2007.10319},
  doi          = {10.48550/arXiv.2007.10319}
}

@article{simonyan2015vgg,
  title        = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  author       = {Simonyan, Karen and Zisserman, Andrew},
  journal      = {International Conference on Learning Representations (ICLR)},
  year         = {2015},
  url          = {https://arxiv.org/abs/1409.1556}
}

@article{zhang2019normalization,
  title        = {Understanding the Effectiveness of Data Normalization in Deep Learning},
  author       = {Zhang, Xiong and others},
  journal      = {Journal of Machine Learning Research},
  year         = {2019},
  note         = {À compléter selon référence exacte}
}

@book{goodfellow2016deep,
  title        = {Deep Learning},
  author       = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  publisher    = {MIT Press},
  year         = {2016},
  url          = {https://www.deeplearningbook.org/}
}

@book{hastie2009elements,
  title        = {The Elements of Statistical Learning: Data Mining, Inference, and Prediction},
  author       = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  edition      = {2nd},
  publisher    = {Springer},
  year         = {2009},
  url          = {https://web.stanford.edu/~hastie/ElemStatLearn/}
}

@article{mbofung2012,
  title        = {Digital camera image processing of hard-to-cook beans during storage},
  author       = {Mbofung, Carl M. and Ndjouenkeu, Robert and Njintang, Yanou N.},
  journal      = {Journal of Food Engineering},
  volume       = {111},
  number       = {2},
  pages        = {276--283},
  year         = {2012},
  publisher    = {Elsevier},
  doi          = {10.1016/j.jfoodeng.2012.01.012}
}

@article{mendoza2018,
  author       = {Mendoza, F. and others},
  title        = {Prediction of cooking time in beans using Vis/NIRS and PLS regression},
  journal      = {Journal of Food Engineering},
  volume       = {234},
  pages        = {123--130},
  year         = {2018}
}

@article{abdalla2023,
  title        = {TinyML-based non-destructive quality assessment of fresh dates using Vis-NIR sensors},
  author       = {Abdalla, Abdelrahman and Shamseldin, Mohamed and Al-Azzawi, Ammar},
  journal      = {Sensors},
  volume       = {23},
  number       = {15},
  pages        = {6785},
  year         = {2023},
  publisher    = {MDPI},
  doi          = {10.3390/s23156785}
}

@article{tastan2023,
  title        = {Plant disease detection using lightweight CNN models for edge devices},
  author       = {Taştan, Murat and Yıldırım, Tarkan},
  journal      = {Computers and Electronics in Agriculture},
  volume       = {205},
  pages        = {107623},
  year         = {2023},
  publisher    = {Elsevier},
  doi          = {10.1016/j.compag.2023.107623}
}

@article{liu1993,
  title        = {Cooking characteristics of dry beans: influence of structural features and chemical composition},
  author       = {Liu, Keshun and McWatters, Kay H. and Phillips, Richard D.},
  journal      = {Journal of Food Science},
  volume       = {58},
  number       = {1},
  pages        = {103--108},
  year         = {1993},
  publisher    = {Wiley},
  doi          = {10.1111/j.1365-2621.1993.tb03223.x}
}

@inproceedings{howard2019,
  title        = {Searching for MobileNetV3},
  author       = {Howard, Andrew and Sandler, Mark and others},
  booktitle    = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  year         = {2019}
}

@article{gao2019,
  title        = {Application of hyperspectral imaging for prediction of cooking time and water absorption in beans},
  author       = {Gao, Y. and Liu, K. and others},
  journal      = {Food Analytical Methods},
  volume       = {12},
  pages        = {2185--2194},
  year         = {2019},
  publisher    = {Springer},
  doi          = {10.1007/s12161-019-01552-1}
}

@misc{tensorflowlitequant,
  author = {TensorFlow Lite Team},
  title = {TensorFlow Lite Quantization Guide},
  year = {2023},
  note = {\url{https://www.tensorflow.org/lite/performance/quantization}}
}

@misc{openbenchmarks,
  author = {Various},
  title = {Open Model Benchmarks for Mobile Inference},
  year = {2024},
  note = {\url{https://paperswithcode.com/sota}}
}

@inproceedings{fbnet,
  author = {Wu, B. et al.},
  title = {FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search},
  booktitle = {CVPR},
  year = {2019}
}

@inproceedings{han2016deep,
  author    = {Song Han and Jeff Pool and John Tran and William Dally},
  title     = {Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding},
  booktitle = {Proceedings of the International Conference on Learning Representations (ICLR)},
  year      = {2016},
  url       = {https://arxiv.org/abs/1510.00149}
}

@article{banbury2021micronets,
  title        = {Micronets: Neural Network Architectures for Deploying TinyML Applications},
  author       = {Banbury, Colby R. and others},
  journal      = {Proceedings of Machine Learning and Systems},
  volume       = {3},
  pages        = {517--532},
  year         = {2021},
  url          = {https://proceedings.mlsys.org/paper/2021/file/c4d41d9619462c534b7b61d1f772385e-Paper.pdf}
}
