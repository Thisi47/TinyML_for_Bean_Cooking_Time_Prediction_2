\chapter{Revue de la littérature}
\label{chap:revue_litterature}

\section{Introduction}
La revue de littérature a pour objectif de positionner le présent travail dans le paysage scientifique actuel en identifiant les contributions majeures, les lacunes existantes et les perspectives d’amélioration. Dans le cadre de ce mémoire, l’accent est mis sur deux axes complémentaires : (i) les recherches liées à la prédiction du temps de cuisson des légumineuses et aux travaux connexes dans le domaine de l’alimentation, et (ii) l’émergence du \textit{Tiny Machine Learning} (TinyML) comme solution pour le traitement embarqué de données sous des contraintes strictes de mémoire et d’énergie. L’articulation de ces deux domaines ouvre la voie à des applications innovantes dans le secteur agroalimentaire, en particulier pour la cuisson et la qualité des aliments.

\section{Intelligence artificielle et secteur agroalimentaire}
L’intelligence artificielle (IA) a profondément transformé le secteur agroalimentaire en introduisant des outils pour l’automatisation, la classification et l’optimisation des procédés \cite{kamilaris2018}. La vision par ordinateur, notamment, est devenue un outil incontournable pour analyser l’apparence des fruits et légumes, estimer leur maturité, évaluer leur qualité ou encore contrôler certains paramètres de cuisson \cite{rahman2020}.

Les applications sont multiples : détection de maladies végétales, suivi de la croissance, reconnaissance automatique des produits sur les chaînes de production ou encore estimation de la fermeté des denrées après cuisson. Les récents progrès en IA embarquée démontrent que la combinaison de modèles légers et de microcontrôleurs permet une surveillance en temps réel, directement sur le terrain \cite{moeketsi2025, kimutaiforster2024}. Ainsi, l’agroalimentaire bénéficie à la fois des avancées de la vision par ordinateur et des développements de l’IA embarquée.

\section{Prédiction du temps de cuisson des légumineuses et travaux connexes}
La cuisson des légumineuses est un processus complexe, influencé par la variété, la taille, la teneur en eau et les conditions de stockage \cite{singh2019, shimelis2020}. Traditionnellement, la prédiction du temps de cuisson repose sur des méthodes expérimentales basées sur des mesures physico-chimiques (dureté, humidité, structure cellulaire) ou sur des techniques spectroscopiques telles que le proche infrarouge. Ces approches, bien que précises, restent coûteuses, lentes et difficilement transposables en conditions réelles.

Des travaux plus récents utilisent la vision par ordinateur et les réseaux de neurones pour corréler les caractéristiques visuelles (forme, couleur, texture de surface) à la tendreté et au temps de cuisson des haricots \cite{njoroge2021}. Ces approches présentent l’avantage d’être non destructives et automatisables, constituant un atout considérable pour une intégration dans des systèmes embarqués.

Les recherches connexes sur d’autres aliments confirment la faisabilité de cette approche. Par exemple, \cite{patindol2017} ont étudié la texture du riz après cuisson, tandis que \cite{foschia2015} se sont intéressés à la fermeté des pâtes. De même, des travaux sur les fruits et légumes montrent que l’IA peut prédire la maturité ou la tendreté à partir d’images \cite{kaur2020}. Ces études suggèrent que l’apparence visuelle contient des informations suffisamment discriminantes pour estimer la texture et le degré de cuisson, renforçant ainsi la pertinence de l’application aux légumineuses.

Néanmoins, malgré ces avancées, les études spécifiques aux haricots restent rares et fragmentaires. Les méthodes existantes sont soit limitées par la taille des échantillons, soit inadaptées au déploiement sur des dispositifs contraints. Cette lacune souligne la nécessité de développer des modèles optimisés pour le TinyML, capables de prédire en temps réel le temps de cuisson à partir d’images.

\section{Convolution et réseaux de neurones convolutifs (CNN)}
\label{sec:cnn}
La convolution est une opération fondamentale des réseaux de neurones convolutifs (CNN) permettant d’extraire automatiquement des caractéristiques pertinentes d’une image.

\subsection{Définition mathématique}
Pour une image $I \in \mathbb{R}^{H\times W}$ et un noyau (filtre) $K \in \mathbb{R}^{m\times n}$, la \emph{corrélation croisée} (opération généralement utilisée dans les bibliothèques de deep learning) est définie par :
\begin{equation}
    \label{eq:xcorr}
    S(i,j) = (I \star K)(i,j) = \sum_{u=0}^{m-1} \sum_{v=0}^{n-1} I(i+u, j+v)\, K(u,v).
\end{equation}
La \emph{convolution} au sens strict correspond au noyau retourné : $K'(u,v) = K(m{-}1{-}u,\,n{-}1{-}v)$ et $S = I \ast K'$. En pratique, cette distinction n’affecte pas l’apprentissage des filtres.

Pour des tenseurs couleur $I \in \mathbb{R}^{H\times W\times C_{in}}$ et $C_{out}$ filtres, chaque filtre $K^{(c)} \in \mathbb{R}^{k\times k\times C_{in}}$ produit une carte de caractéristiques ; les sorties sont ensuite empilées pour obtenir une sortie de dimension $\mathbb{R}^{H'\times W'\times C_{out}}$.

\subsection{Padding, stride, dilatation}
\begin{itemize}
    \item \textbf{Padding} ($p$) : ajout de bordures pour contrôler la taille de sortie. Avec $k$ impair et $p=\tfrac{k-1}{2}$, on conserve $H'=H$ et $W'=W$.
    \item \textbf{Stride} ($s$) : pas de déplacement du filtre. $H' = \left\lfloor \tfrac{H - k + 2p}{s} + 1 \right\rfloor$ et idem pour $W'$.
    \item \textbf{Dilatation} ($d$) : espacement des éléments du filtre (réception plus large) avec un noyau effectif $k_{\mathrm{eff}} = k + (k-1)(d-1)$.
\end{itemize}

\subsection{Coût, paramètres et convolutions séparables}
Le nombre de paramètres d’une convolution standard $k \times k$ est :
\begin{equation}
    \mathrm{Params}_{\text{std}} = k^2 \cdot C_{in} \cdot C_{out}.
\end{equation}
Le nombre d’opérations de type MACs est approximativement $H' \times W' \times \mathrm{Params}_{\text{std}}$.

Les \textbf{convolutions séparables en profondeur} (\emph{depthwise separable}), utilisées notamment par MobileNet \cite{howard2017mobilenets}, factorisent une convolution standard en : (i) une convolution \emph{depthwise} $k \times k$ appliquée canal par canal, puis (ii) une convolution \emph{pointwise} $1 \times 1$ pour mélanger les canaux. Le nombre de paramètres devient :
\begin{equation}
    \mathrm{Params}_{\text{dw-sep}} = k^2 C_{in} + C_{in} C_{out} \quad \text{au lieu de } k^2 C_{in} C_{out}.
\end{equation}
Le rapport de réduction théorique en paramètres et opérations est donc :
\begin{equation}
    \frac{\mathrm{Params}_{\text{dw-sep}}}{\mathrm{Params}_{\text{std}}} \approx \frac{1}{C_{out}} + \frac{1}{k^2},
\end{equation}
ce qui explique les gains substantiels pour des noyaux $3 \times 3$ et de grands $C_{out}$.

\subsection{Autres blocs légers}
\begin{itemize}
    \item \textbf{Bottlenecks résiduels} (Inverted Residuals, SE, etc.) : améliorent le flux d’information et la précision à coût quasi constant.
    \item \textbf{Global Average Pooling} : remplace des couches entièrement connectées coûteuses par une moyenne spatiale.
    \item \textbf{Normalisations/activations} : Batch/Group Normalization, ReLU/ReLU6/SiLU — souvent adaptées pour la stabilité sur matériel contraint.
\end{itemize}

\subsection{Fonction d’activation \textit{Softmax}}
La fonction \textit{softmax} est une activation essentielle en sortie des CNN lorsqu’il s’agit de problèmes de classification multi-classes \cite{goodfellow2016deep, bishop2006pattern}. Elle transforme un vecteur de scores réels (appelés \emph{logits}) en une distribution de probabilité sur les classes.

Soit un vecteur de sorties $z = (z_1, z_2, \dots, z_K) \in \mathbb{R}^K$, où $K$ est le nombre de classes. La fonction softmax est définie par :
\begin{equation}
    \label{eq:softmax}
    \mathrm{softmax}(z_i) = \frac{\exp(z_i)}{\sum_{j=1}^{K} \exp(z_j)}, \quad \text{pour } i = 1, \dots, K.
\end{equation}

Cette transformation garantit deux propriétés fondamentales :
\begin{itemize}
    \item \textbf{Positivité} : $\mathrm{softmax}(z_i) > 0$ pour tout $i$.
    \item \textbf{Normalisation} : $\sum_{i=1}^{K} \mathrm{softmax}(z_i) = 1$.
\end{itemize}

Ainsi, chaque sortie peut être interprétée comme une probabilité associée à la classe correspondante. Dans l’entraînement, la fonction softmax est souvent couplée à la fonction de perte \emph{entropie croisée}, qui mesure la divergence entre la distribution prédite et la distribution réelle (étiquettes une-hot). Cette combinaison est particulièrement efficace pour l’optimisation de réseaux de neurones profonds \cite{goodfellow2016deep}.

Enfin, bien que très répandue, la softmax présente une sensibilité aux valeurs extrêmes des logits (phénomène de saturation). Des alternatives comme la \emph{sigmoid multi-label} ou la \emph{temperature scaling} peuvent être utilisées selon les besoins.

\subsection{Encodage des classes : utilisation du Label Encoding}
Dans ce travail, les classes textuelles représentant les différentes variétés de haricots (par exemple : \texttt{Dor701}, \texttt{TY339612}, etc.) ont été converties en entiers grâce à la méthode \textbf{Label Encoding}. Cette transformation consiste à associer un entier unique à chaque classe :
\[
    \texttt{Dor701} \mapsto 0, \quad
    \texttt{TY339612} \mapsto 1, \quad
    \dots
\]

Le \emph{Label Encoding} présente plusieurs avantages :
\begin{itemize}
    \item Il est \textbf{simple et efficace}, nécessitant peu de mémoire et facilitant le prétraitement.
    \item Il est parfaitement adapté aux modèles de \textbf{deep learning} où les étiquettes sont ensuite converties implicitement en vecteurs lors de la phase d’entraînement, notamment lorsqu’elles sont couplées à une couche de sortie avec \textit{softmax}.
    \item Dans notre approche, il s’intègre naturellement au pipeline basé sur \textbf{MobileNetV2} comme extracteur de caractéristiques, car les sorties du réseau correspondent directement à des indices entiers de classes.
\end{itemize}

Toutefois, il convient de noter que le \emph{Label Encoding} introduit artificiellement une notion d’ordre entre les classes (par exemple, $0 < 1 < 2$), ce qui peut poser problème pour certains modèles linéaires sensibles aux relations ordinales \cite{jones2020label}. Dans notre cas, ce biais est compensé par l’utilisation d’un réseau de neurones convolutif, pour lequel les indices sont simplement traités comme des catégories distinctes, sans relation hiérarchique implicite.

En résumé, le choix du \emph{Label Encoding} dans ce projet permet de garantir une représentation compacte des étiquettes, compatible avec la couche de sortie \textit{softmax} et la fonction de perte par entropie croisée, assurant ainsi un apprentissage efficace de la classification des variétés de haricots.

\section{TinyML : principes, avantages, cas d’usage et limites}
Le \textit{Tiny Machine Learning} (TinyML) désigne l’exécution de modèles d’apprentissage automatique directement sur des dispositifs embarqués à ressources limitées (microcontrôleurs, capteurs intelligents) \cite{banbury2021}. L’objectif est de réaliser des inférences en temps réel localement, avec une faible empreinte mémoire et énergétique, rendant l’IA accessible même dans des environnements à faible connectivité.

\subsection{Contraintes matérielles typiques}
Les microcontrôleurs ciblés disposent souvent de : (i) \textasciitilde32–1024\,kB de SRAM, (ii) \textasciitilde128\,kB à quelques Mo de Flash, (iii) fréquences de l’ordre de dizaines à quelques centaines de MHz, (iv) parfois aucune FPU ou seulement une FPU simple précision. Ces contraintes guident la conception des modèles (taille, latence, consommation).

\subsection{Avantages et cas d’utilisation}
\begin{itemize}
    \item \textbf{Traitement local} : réduction de la latence et de la dépendance au cloud.
    \item \textbf{Efficacité énergétique} : consommation minimale adaptée aux dispositifs alimentés par batterie.
    \item \textbf{Confidentialité accrue} : les données ne quittent pas le dispositif, limitant les risques de fuite.
    \item \textbf{Accessibilité économique} : microcontrôleurs peu coûteux adaptés à une large diffusion.
\end{itemize}
Applications emblématiques :
\begin{itemize}
    \item \textbf{Agriculture} : détection de maladies, estimation de la qualité des récoltes, suivi en temps réel \cite{moeketsi2025, kimutaiforster2024}.
    \item \textbf{Agroalimentaire} : classification des produits, prédiction de la texture et du temps de cuisson.
    \item \textbf{Santé} : suivi des signaux physiologiques sur dispositifs portables.
    \item \textbf{IoT industriel} : capteurs intelligents (maintenance prédictive, détection d’anomalies).
\end{itemize}

\subsection{Techniques d’optimisation}
\paragraph{Quantification (INT8, FP16)}\label{subsec:quant}  
La quantification convertit les tenseurs (poids/activations) en représentations numériques plus compactes. Le modèle flottant \( x \in \mathbb{R} \) est approximé par une valeur quantifiée \( q \) dans \([q_{\min}, q_{\max}]\) avec une échelle \( s > 0 \) et un \emph{zero-point} \( z \) :
\begin{equation}
    \label{eq:affine_quant}
    q = \mathrm{clip}\Big(\big\lfloor \tfrac{x}{s} + z \big\rceil, q_{\min}, q_{\max}\Big), \quad \hat{x} = s(q - z).
\end{equation}
Cas courants :
\begin{itemize}
    \item \textbf{INT8 (entier 8 bits)} : \(q_{\min} = -128\), \(q_{\max} = 127\) (quantification symétrique avec \(z=0\) ou quantification affine asymétrique). Gain mémoire d’environ \(\times 4\) par rapport au FP32 ; accélérations substantielles si l’ISA/MAC INT8 est disponible (CMSIS-NN, etc.).
    \item \textbf{FP16 (demi-précision)} : stockage en 16 bits flottants. Gain mémoire d’environ \(\times 2\) ; accélération dépendante du support FPU/ISA. Souvent utilisé pour les couches sensibles (première et dernière).
\end{itemize}  
\textbf{Granularité.} Quantification \emph{per-tensor} (simple, moins précise) versus \emph{per-channel} (préférée pour les couches convolutionnelles).  
\textbf{Stratégies.} \emph{Post-Training Quantization} (PTQ) avec calibration (quelques centaines d’échantillons représentatifs) ; \emph{Quantization-Aware Training} (QAT) qui simule la quantification pendant l’entraînement pour limiter la perte de précision.

\paragraph{Pruning (élagage)}  
Suppression de poids ou redondances pour réduire mémoire et calculs. Le pruning \emph{non structuré} (mise à zéro de poids individuels) réduit la taille mais n’accélère pas toujours la latence ; le pruning \emph{structuré} (suppression de canaux, filtres ou blocs) permet des gains réels sur matériel. Des approches progressives maintiennent la précision \cite{han2016deep}.

\paragraph{Distillation de connaissances}  
Un modèle \emph{student} plus compact apprend d’un modèle \emph{teacher} plus large en utilisant des cibles douces (température \(T\)) et une combinaison de pertes (par ex. entropie croisée et divergence KL sur logits). Cette technique préserve souvent la performance tout en allégeant l’architecture.

\subsection{Avancées et perspectives du TinyML}
Évolutions notables :
\begin{itemize}
    \item \textbf{Quantization-Aware Training (QAT)} et \textbf{mixed precision} : INT8 majoritaire, FP16/FP32 pour couches sensibles.
    \item \textbf{NAS contraint} (TinyNAS, Mobile-friendly NAS) : recherche d’architectures sous contraintes de latence, RAM et Flash.
    \item \textbf{Tiny Transfer Learning} : réutilisation de modèles pré-entraînés allégés et adaptation avec peu d’échantillons.
    \item \textbf{Kernels optimisés et compilateurs} : CMSIS-NN, TFLite Micro (TFLM), microTVM ; \emph{operator fusion} et planification mémoire avancée.
    \item \textbf{Mesures sur cible} : prise en compte des métriques embarquées (latence réelle, pic RAM, Flash) dès les cycles d’itération.
\end{itemize}
Ces avancées permettent d’envisager des cas d’usage complexes (vision embarquée, audio, capteurs multimodaux) tout en maintenant un compromis adapté entre précision, latence et énergie sur MCU.

\section{Modèles légers pour dispositifs contraints}
La conception de modèles adaptés au TinyML repose sur des architectures légères et optimisées :
\begin{itemize}
    \item \textbf{MobileNet} : basé sur les convolutions séparables en profondeur, réduisant drastiquement le nombre de paramètres \cite{howard2017mobilenets}.
    \item \textbf{EfficientNet} : propose une mise à l’échelle équilibrée en profondeur, largeur et résolution pour maximiser l’efficacité \cite{tan2019mnasnet}.
    \item \textbf{NASNetMobile} : utilise la recherche automatique d’architectures (NAS) pour identifier les modèles optimaux pour mobiles \cite{zoph2018}.
\end{itemize}
Ces architectures, combinées à la quantification et au pruning, permettent d’obtenir des modèles performants et économes en ressources, adaptés aux capteurs IoT agricoles ou culinaires \cite{moeketsi2025}.

\section{Métriques d’évaluation des modèles}
L’évaluation des modèles de prédiction repose sur plusieurs métriques standardisées, adaptées aux problèmes de régression ou de classification. Nous introduisons formellement les métriques utilisées dans ce mémoire et discutons leurs propriétés et limites.

\subsection{Métriques de régression}
Soit un jeu d’observations \(\{(y_i,\hat{y}_i)\}_{i=1}^n\).
\begin{itemize}
    \item \textbf{Erreur quadratique moyenne (MSE)} :
          \[
              \mathrm{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2.
          \]
          Sensible aux grandes erreurs, elle pénalise fortement les écarts importants dans les temps de cuisson.
    \item \textbf{Racine de l’erreur quadratique moyenne (RMSE)} :
          \[
              \mathrm{RMSE} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}.
          \]
          Interprétable dans l’unité de \(y\) (minutes de cuisson), facilitant la communication des résultats.
    \item \textbf{Erreur absolue moyenne (MAE)} :
          \[
              \mathrm{MAE} = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|.
          \]
          Robuste aux valeurs aberrantes, elle mesure l’écart moyen absolu.
    \item \textbf{Erreur absolue moyenne en pourcentage (MAPE)} :
          \[
              \mathrm{MAPE} = \frac{100}{n} \sum_{i=1}^{n} \left| \frac{y_i - \hat{y}_i}{y_i} \right|.
          \]
          Exprime l’erreur en pourcentage. \textit{Limites :} non définie si \(y_i=0\) ; instable si \(|y_i|\) est très faible. Une alternative symétrisée (SMAPE) peut être utilisée :
          \[
              \mathrm{SMAPE} = \frac{100}{n} \sum_{i=1}^{n} \frac{|y_i - \hat{y}_i|}{(|y_i| + |\hat{y}_i|)/2}.
          \]
    \item \textbf{Coefficient de détermination (\(R^2\))} :
          \[
              R^2 = 1 - \frac{\sum_{i=1}^n (y_i - \hat{y}_i)^2}{\sum_{i=1}^n (y_i - \bar{y})^2}, \qquad \bar{y} = \frac{1}{n} \sum_{i=1}^n y_i.
          \]
          Mesure la proportion de variance expliquée. Variante \emph{ajustée} :
          \[
              R^2_{\text{adj}} = 1 - (1 - R^2) \frac{n - 1}{n - p - 1},
          \]
          où \(p\) est le nombre de prédicteurs \emph{effectifs}. Utile pour comparer des modèles de complexité différente.
\end{itemize}

\subsection{Métriques de classification}
Pour une matrice de confusion multiclasses \(\mathbf{C}\) avec \(C\) classes, et en notant \(TP_c\), \(FP_c\), \(FN_c\), \(TN_c\) les valeurs par classe \(c\) :
\begin{itemize}
    \item \textbf{Précision (Precision)} par classe : \(\mathrm{Prec}_c = \frac{TP_c}{TP_c + FP_c}\) ; \textbf{Rappel (Recall)} : \(\mathrm{Rec}_c = \frac{TP_c}{TP_c + FN_c}\) ; \textbf{F1} : \(\mathrm{F1}_c = 2 \frac{\mathrm{Prec}_c \times \mathrm{Rec}_c}{\mathrm{Prec}_c + \mathrm{Rec}_c}\).
    \item \textbf{Agrégations} : \emph{macro} (moyenne non pondérée des classes), \emph{micro} (calcul sur l’ensemble des instances), \emph{pondérée} (pondération par support de chaque classe).
          \[
              \mathrm{F1}_{\text{macro}} = \frac{1}{C} \sum_{c=1}^C \mathrm{F1}_c, \quad \mathrm{Precision}_{\text{micro}} = \frac{\sum_c TP_c}{\sum_c (TP_c + FP_c)}.
          \]
    \item \textbf{Exactitude (Accuracy)} : \(\mathrm{Acc} = \frac{\sum_c TP_c}{\sum_c (TP_c + FP_c + FN_c)}\) ; sensible au déséquilibre des classes.
    \item \textbf{Balanced Accuracy} : moyenne des rappels par classe, utile en cas de classes déséquilibrées.
    \item \textbf{ROC–AUC / PR–AUC} (binaire ou one-vs-rest multi-classes) : évaluent la capacité de classement ; PR–AUC est informatif en cas de forte rareté d’une classe.
\end{itemize}
Dans ce mémoire, ces métriques serviront à la classification éventuelle des variétés ou états de cuisson, ainsi qu’à la régression du temps de cuisson, facilitant une comparaison cohérente.

\section{Bonnes pratiques d’évaluation embarquée}
Outre les métriques prédictives, l’évaluation TinyML doit \emph{impérativement} considérer :
\begin{itemize}
    \item \textbf{Latence d’inférence sur cible} (en ms) et \textbf{throughput} (inférences/seconde) ;
    \item \textbf{Pic de RAM} (mémoire vive) et \textbf{empreinte Flash} (taille du binaire modèle + runtime) ;
    \item \textbf{Consommation énergétique} (en mJ par inférence), lorsque mesurable ;
    \item \textbf{Robustesse} aux variations d’illumination, angle de prise de vue et au bruit de capteurs, conditions typiques du domaine d’application réel.
\end{itemize}
Ces critères guideront les arbitrages entre précision et contraintes matérielles (voir \S\ref{subsec:quant}).

\section{Synthèse des travaux antérieurs}
\begin{table}[H]
    \centering
    \scriptsize
    \caption{Synthèse des travaux pertinents pour la revue de littérature}
    \label{tab:revue_litterature}
    \begin{tabularx}{\textwidth}{|p{0.5cm}|p{0.7cm}|p{2.0cm}|X|X|X|X|X|}
        \hline
        \textbf{Réf.}                & \textbf{Année} & \textbf{Titre}               & \textbf{Objectif}                & \textbf{Méthodologie}       & \textbf{Résultats}           & \textbf{Limites}                & \textbf{Pertinence}              \\
        \hline
        \cite{kamilaris2018}         & 2018           & Deep learning in agriculture & Survol IA agriculture            & Revue                       & IA utile classification      & Peu de focus sur la cuisson    & Contexte agroalimentaire         \\
        \hline
        \cite{rahman2020}            & 2020           & Food cooking estimation      & Estimer temps de cuisson via images & Analyse d’images         & Corrélation détectée         & Échantillon limité              & Lien direct avec cuisson        \\
        \hline
        \cite{banbury2021micronets}  & 2021           & TinyML principles            & Définir TinyML                   & Discussion                  & TinyML possible sur MCU       & Manque d’implémentations concrètes & Cadre TinyML                   \\
        \hline
        \cite{howard2017mobilenets}  & 2017           & MobileNet CNN                & CNN léger pour mobiles           & Architecture                & Bonne précision, faible coût  & Coût élevé pour certains MCU    & Base pour modèles légers        \\
        \hline
        \cite{tan2019mnasnet}        & 2019           & EfficientNet scaling         & Optimiser mise à l’échelle CNN   & Architecture optimisée      & Meilleure efficacité         & Toujours lourd pour TinyML      & Optimisation CNN                \\
        \hline
        \cite{zoph2018}              & 2018           & NASNetMobile                 & Optimisation via NAS             & Recherche automatique       & Architecture optimisée       & Complexité de la NAS            & Modèles mobiles                \\
        \hline
        \cite{jacob2018quantization} & 2018           & Quantization NN              & Réduire taille modèles           & Quantification INT8/FP16    & Réduction mémoire x4         & Perte de précision possible     & Compression mémoire             \\
        \hline
        \cite{han2016deep}           & 2016           & Pruning deep nets            & Réduction des paramètres         & Pruning                     & Réduction paramètres x10     & Perte de précision si pruning excessif & Réduction mémoire          \\
        \hline
        \cite{patel2019}             & 2019           & Grain classification         & Classifier variétés de grains    & CNN grains                  & Bonne précision              & Peu généralisable               & Classification grains/haricots \\
        \hline
        \cite{kaur2020}              & 2020           & Fruit maturity estimation    & Prédire maturité et tendreté     & CNN fruits/légumes          & Prédictions fiables          & Dataset limité                  & Lien cuisson/texture           \\
        \hline
        \cite{gonzalezbarron2021}    & 2021           & Food defect detection        & Détection de défauts alimentaires & Analyse d’images          & Détection robuste            & Applicabilité restreinte        & Qualité alimentaire            \\
        \hline
        \cite{yu2019}                & 2019           & Texture prediction food      & Corréler images et texture       & Vision + spectroscopie      & Corrélations confirmées      & Peu d’applications concrètes    & Lien cuisson/texture           \\
        \hline
        \cite{moeketsi2025}          & 2025           & TinyML micronutrient sensing & TinyML pour détection micronutriments & Revue PRISMA           & Modèles hybrides performants & Reporting incomplet             & Insight TinyML en agriculture  \\
        \hline
        \cite{kimutaiforster2024}    & 2024           & Domain-Adaptive TinyML       & Détection maladies via TinyML    & 2D-CNN + adaptation domaine & Performance correcte         & Chute de performance en conditions réelles & Adaptabilité TinyML agri \\
        \hline
        \cite{capogrosso2023}        & 2023           & Survey TinyML                & Taxonomie TinyML                 & Revue PRISMA                & Mapping optimisations        & Peu d’applications agricoles    & Ressources méthodologiques     \\
        \hline
        \cite{heydari2025sensors}    & 2025           & TinyML on-device inference   & Avantages de l’inférence embarquée & Revue appli              & Gains en latence et vie privée & Peu d’exemples en agro          & Justification inférence locale \\
        \hline
        \cite{sensors2025_tinydl}    & 2025           & From TinyML to TinyDL        & Optimisation TinyDL              & Comparatif architectures    & Framework global             & Peu d’applications cuisson       & Inspiration pour l’optimisation modèles \\
        \hline
    \end{tabularx}
\end{table}

\section{Conclusion}
La littérature montre que l’IA et la vision par ordinateur offrent un potentiel considérable pour prédire le temps de cuisson et évaluer la qualité des aliments. Toutefois, les approches existantes présentent des limites : échantillons restreints, complexité des modèles et manque d’adaptation aux dispositifs contraints. Par ailleurs, la majorité des travaux portent sur d’autres aliments que les légumineuses, laissant un champ de recherche peu exploré.

Le TinyML apparaît comme une réponse pertinente à ces limitations. Grâce à ses techniques d’optimisation (quantification, pruning, distillation) et à ses architectures légères (MobileNet, NAS contraint), il permet d’envisager des systèmes intelligents, embarqués et autonomes, adaptés à des contextes réels. Le présent mémoire s’inscrit dans cette perspective en proposant une approche originale : exploiter le TinyML pour prédire le temps de cuisson des haricots à partir d’images, en évaluant conjointement la précision de la prédiction et les contraintes embarquées (latence, RAM, Flash, énergie).
