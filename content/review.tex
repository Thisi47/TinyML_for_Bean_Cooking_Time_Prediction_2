\chapter{Revue de la littérature}
\label{chap:revue_litterature}

\section{Introduction}
La revue de littérature a pour objectif de positionner le présent travail dans le paysage scientifique actuel, en identifiant les contributions majeures, les lacunes existantes et les perspectives d’amélioration. Dans le cadre de ce mémoire, l’accent est mis sur deux axes complémentaires : (i) les recherches liées à la prédiction du temps de cuisson des légumineuses et travaux connexes dans l’alimentation, et (ii) l’émergence du \textit{Tiny Machine Learning} (TinyML) comme solution au traitement embarqué de données avec des contraintes strictes en mémoire et en énergie. L’articulation de ces deux domaines ouvre la voie à des applications innovantes dans le secteur agroalimentaire, en particulier pour la cuisson et la qualité des aliments.

\section{Intelligence artificielle et secteur agroalimentaire}
L’intelligence artificielle (IA) a profondément transformé le secteur agroalimentaire en introduisant des outils pour l’automatisation, la classification et l’optimisation des procédés \cite{kamilaris2018}. La vision par ordinateur, notamment, est devenue un outil incontournable pour analyser l’apparence des fruits et légumes, estimer leur maturité, évaluer leur qualité ou encore contrôler certains paramètres de cuisson \cite{rahman2020}.

Les applications sont multiples : détection de maladies végétales, suivi de la croissance, reconnaissance automatique des produits sur les chaînes de production, ou encore estimation de la fermeté des denrées après cuisson. Les récents progrès en IA embarquée démontrent que la combinaison de modèles légers et de microcontrôleurs permet de réaliser de la surveillance en temps réel, directement sur le terrain \cite{moeketsi2025, kimutaiforster2024}. Ainsi, l’agroalimentaire bénéficie à la fois des avancées de la vision par ordinateur et des développements de l’IA embarquée.

\section{Prédiction du temps de cuisson des légumineuses et travaux connexes}
La cuisson des légumineuses est un processus complexe, influencé par la variété, la taille, la teneur en eau et les conditions de stockage \cite{singh2019, shimelis2020}. Traditionnellement, la prédiction du temps de cuisson repose sur des méthodes expérimentales basées sur des mesures physico-chimiques (dureté, humidité, structure cellulaire) ou sur des techniques spectroscopiques telles que le proche infrarouge. Ces approches, bien que précises, restent coûteuses, lentes et difficilement transposables en conditions réelles.

Des travaux plus récents exploitent la vision par ordinateur et les réseaux de neurones pour corréler les caractéristiques visuelles (forme, couleur, texture de surface) à la tendreté et au temps de cuisson des haricots \cite{njoroge2021}. Ces approches présentent l’avantage d’être non destructives et automatisables, ce qui constitue un atout considérable pour une intégration dans des systèmes embarqués.

Les recherches connexes sur d’autres aliments confirment la faisabilité de cette approche. Par exemple, \cite{patindol2017} ont étudié la texture du riz après cuisson, tandis que \cite{foschia2015} se sont intéressés à la fermeté des pâtes. De même, des travaux sur les fruits et légumes montrent que l’IA peut prédire la maturité ou la tendreté à partir d’images \cite{kaur2020}. Ces études suggèrent que l’apparence visuelle contient des informations suffisamment discriminantes pour estimer la texture et le degré de cuisson, ce qui renforce la pertinence de l’application aux légumineuses.

Néanmoins, malgré ces avancées, les études spécifiques aux haricots restent rares et fragmentaires. Les méthodes existantes sont soit limitées par la taille des échantillons, soit inadaptées au déploiement sur des dispositifs contraints. Cette lacune souligne la nécessité de développer des modèles optimisés pour le TinyML, capables de prédire en temps réel le temps de cuisson à partir d’images.

\section{TinyML : principes, avantages, cas d’usage et limites}
Le \textit{Tiny Machine Learning} (TinyML) désigne l’exécution de modèles d’apprentissage automatique directement sur des dispositifs embarqués à ressources limitées (microcontrôleurs, capteurs intelligents) \cite{banbury2021}. L’objectif est de réaliser des inférences en temps réel localement, avec une faible empreinte mémoire et énergétique, rendant l’IA accessible même dans des environnements à faible connectivité.

\subsection{Avantages et cas d’utilisation}
Les principaux avantages du TinyML sont :
\begin{itemize}
	\item \textbf{Traitement local} : réduction de la latence et de la dépendance au cloud.
	\item \textbf{Efficacité énergétique} : consommation minimale adaptée aux dispositifs alimentés par batterie.
	\item \textbf{Confidentialité accrue} : les données ne quittent pas le dispositif, limitant les risques de fuite.
	\item \textbf{Accessibilité économique} : microcontrôleurs peu coûteux adaptés à une large diffusion.
\end{itemize}

Les applications sont variées :
\begin{itemize}
	\item \textbf{Agriculture} : détection de maladies, estimation de la qualité des récoltes, suivi en temps réel \cite{moeketsi2025, kimutaiforster2024}.
	\item \textbf{Agroalimentaire} : classification des produits, prédiction de la texture et du temps de cuisson.
	\item \textbf{Santé} : suivi des signaux physiologiques sur dispositifs portables.
	\item \textbf{IoT industriel} : capteurs intelligents embarqués dans des systèmes connectés.
\end{itemize}

\subsection{Contraintes et limites}
Malgré son potentiel, le TinyML se heurte à plusieurs limites :
\begin{itemize}
	\item Mémoire et puissance de calcul limitées, restreignant la taille et la complexité des modèles.
	\item Nécessité de recourir à des optimisations pouvant induire une perte de précision.
	\item Disponibilité limitée de jeux de données spécialisés, notamment dans le domaine de la cuisson des légumineuses.
\end{itemize}

\subsection{Techniques d’optimisation}
Pour rendre l’exécution des modèles possible sur microcontrôleurs, plusieurs techniques sont utilisées :
\begin{itemize}
	\item \textbf{Quantification} : conversion des poids du modèle en entiers (INT8) ou en flottants réduits (FP16) pour diminuer l’empreinte mémoire et accélérer l’inférence \cite{jacob2018quantization}.
	\item \textbf{Pruning} : suppression des connexions et paramètres redondants afin de réduire la taille du réseau tout en préservant ses performances \cite{han2016deep}.
	\item \textbf{Distillation de connaissances} : entraînement d’un petit modèle (\textit{student}) à partir d’un modèle plus complexe (\textit{teacher}), pour conserver les performances tout en allégeant l’architecture.
\end{itemize}

Ces optimisations assurent un compromis entre efficacité computationnelle et précision, indispensable pour l’implémentation en contexte embarqué.

\section{Modèles légers pour dispositifs contraints}
La conception de modèles adaptés au TinyML repose sur des architectures légères et optimisées :
\begin{itemize}
	\item \textbf{MobileNet} : basé sur les convolutions séparables en profondeur, permettant de réduire drastiquement le nombre de paramètres \cite{howard2017mobilenets}.
	\item \textbf{EfficientNet} : propose une mise à l’échelle équilibrée en profondeur, largeur et résolution pour maximiser l’efficacité \cite{tan2019mnasnet}.
	\item \textbf{NASNetMobile} : utilise la recherche automatique d’architectures (NAS) pour identifier les modèles optimaux pour mobiles \cite{zoph2018}.
\end{itemize}

Ces architectures, associées à la quantification et au pruning, permettent d’obtenir des modèles performants et économes en ressources, adaptés aux capteurs IoT agricoles ou culinaires \cite{moeketsi2025}.

\section{Synthèse des travaux antérieurs}
\begin{table}[H]
	\centering
	\scriptsize
	\caption{Synthèse des travaux pertinents pour la revue de littérature}
	\label{tab:revue_litterature}
	\begin{tabularx}{\textwidth}{|p{0.5cm}|p{0.7cm}|p{2.0cm}|X|X|X|X|X|}
		\hline
		\textbf{Réf.}                & \textbf{Année} & \textbf{Titre}               & \textbf{Objectif}                & \textbf{Méthodologie}       & \textbf{Résultats}           & \textbf{Limites}                & \textbf{Pertinence}              \\
		\hline
		\cite{kamilaris2018}         & 2018           & Deep learning in agriculture & Survol IA agriculture            & Revue                       & IA utile classification      & Peu focus cuisson               & Contexte agroalimentaire         \\
		\hline
		\cite{rahman2020}            & 2020           & Food cooking estimation      & Estimer temps cuisson via images & Analyse d’images            & Corrélation détectée         & Échantillon limité              & Lien cuisson direct              \\
		\hline
		\cite{banbury2021micronets}  & 2021           & TinyML principles            & Définir TinyML                   & Discussion                  & TinyML possible MCU          & Manque implémentations          & Cadre TinyML                     \\
		\hline
		\cite{howard2017mobilenets}  & 2017           & MobileNet CNN                & CNN léger mobiles                & Architecture                & Bonne précision faible coût  & Coûteux MCU                     & Base modèles légers              \\
		\hline
		\cite{tan2019mnasnet}        & 2019           & EfficientNet scaling         & Optimiser mise à l’échelle CNN   & Architecture optimisée      & Meilleure efficacité         & Toujours lourd TinyML           & Optimisation CNN                 \\
		\hline
		\cite{zoph2018}              & 2018           & NASNetMobile                 & Optimisation via NAS             & Recherche auto              & Architecture optimisée       & Complexité NAS                  & Modèles mobiles                  \\
		\hline
		\cite{jacob2018quantization} & 2018           & Quantization NN              & Réduire taille modèles           & Quantification INT8/FP16    & Réduction mémoire x4         & Perte précision possible        & Compression mémoire              \\
		\hline
		\cite{han2016deep}           & 2016           & Pruning deep nets            & Réduction paramètres             & Pruning                     & Réduction paramètres x10     & Perte précision si trop pruning & Réduction mémoire                \\
		\hline
		\cite{patel2019}             & 2019           & Grain classification         & Classifier variétés grains       & CNN grains                  & Bonne précision              & Peu généralisable               & Classification grains/haricots   \\
		\hline
		\cite{kaur2020}              & 2020           & Fruit maturity estimation    & Prédire maturité/ tendreté        & CNN fruits/légumes          & Prédictions fiables          & Dataset limité                  & Lien cuisson/texture             \\
		\hline
		\cite{gonzalezbarron2021}    & 2021           & Food defect detection        & Détection défauts                & Analyse images              & Détection robuste            & Applicabilité restreinte        & Qualité alimentaire              \\
		\hline
		\cite{yu2019}                & 2019           & Texture prediction food      & Corréler images et texture       & Vision + spectro            & Corrélations confirmées      & Peu d’applications concrètes    & Lien cuisson/texture             \\
		\hline
		\cite{moeketsi2025}          & 2025           & TinyML micronutrient sensing & TinyML détection micronutriments & Revue PRISMA                & Modèles hybrides performants & Reporting incomplet             & Insight TinyML agri              \\
		\hline
		\cite{kimutaiforster2024}    & 2024           & Domain-Adaptive TinyML       & Détection maladies TinyML        & 2D-CNN + adaptation domaine & Performance correcte         & Chute conditions réelles        & Adaptabilité TinyML agri         \\
		\hline
		\cite{capogrosso2023}        & 2023           & Survey TinyML                & Taxonomie TinyML                 & Revue PRISMA                & Mapping optimisation         & Peu d’applis agricoles          & Ressources méthodologiques       \\
		\hline
		\cite{heydari2025sensors}    & 2025           & TinyML on-device inference   & Avantages TinyML embarqué        & Revue appli                 & Gain latence et vie privée   & Peu exemples agro               & Justifier inférence locale       \\
		\hline
		\cite{sensors2025_tinydl}    & 2025           & From TinyML to TinyDL        & Optimisation TinyDL              & Comparatif architectures    & Framework global             & Peu applis cuisson              & Inspiration optimisation modèles \\
		\hline
	\end{tabularx}
\end{table}


\section{Conclusion}
La littérature montre que l’IA et la vision par ordinateur offrent un potentiel considérable pour la prédiction du temps de cuisson et la qualité des aliments. Toutefois, les approches existantes présentent des limites : échantillons restreints, complexité des modèles et absence d’adaptation aux dispositifs contraints. De plus, la majorité des travaux portent sur d’autres aliments que les légumineuses, laissant un champ de recherche encore peu exploré.

Le TinyML apparaît comme une réponse pertinente à ces limitations. Grâce à ses techniques d’optimisation et à ses architectures légères, il permet d’envisager des systèmes intelligents, embarqués et autonomes, adaptés à des contextes réels. Le présent mémoire s’inscrit dans cette perspective en proposant une approche originale : exploiter le TinyML pour prédire le temps de cuisson des haricots à partir d’images, comblant ainsi un vide identifié dans la littérature et ouvrant la voie à des applications pratiques dans l’agroalimentaire.
