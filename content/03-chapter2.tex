\chapter{Développement et implémentation}
\label{chap:developpement}

Ce chapitre présente la mise en œuvre concrète du système de prédiction du temps de cuisson des haricots, depuis la préparation des données jusqu’au déploiement embarqué. Il s’appuie sur la méthodologie définie au Chapitre~\ref{chap:methodologie} et reprend strictement les choix techniques (prétraitements, architectures candidates, schéma d’entraînement et optimisation TinyML).

L’approche adoptée est \textbf{hiérarchique} : une première étape de \textbf{classification} permet de distinguer les images de haricots des autres objets, suivie d’une \textbf{régression} sur les images de haricots afin de prédire le temps de cuisson.

\section{Environnement de développement}
\label{sec:env_dev}

\subsection{Matériel}
Les expérimentations ont été menées sur :
\begin{itemize}
	\item \textbf{Machine locale} : Intel Core i7 (4 cœurs), 16~Go RAM.
	\item \textbf{Google Colab} : session \texttt{Tesla T4} (15~Go VRAM, 12~Go RAM, 118~Go stockage).
	\item \textbf{Samsung Galaxy Note 9} : Octa-core, 6 Go RAM, 128~Go stockage, Android 10.
\end{itemize}

\subsection{Logiciels et versions}
Sauf mention contraire, les versions utilisées sont celles définies en méthodologie :
\begin{itemize}
	\item \textbf{Python} 3.10
	\item \textbf{TensorFlow} 2.19 pour l'entrainement et \textbf{TensorFlow} 2.13 pour la quantification \& API Keras (compatibles \texttt{TensorFlow Lite})
	\item \textbf{Pandas} 2.1, \textbf{NumPy} 1.25, \textbf{Matplotlib} 3.8
\end{itemize}

\section{Préparation des données}
\label{sec:pretraitement}

La préparation des données est subdivisée en deux pipelines distincts, correspondant aux \textbf{deux modèles} :

\begin{enumerate}
	\item \textbf{Prétraitement pour la classification} : consiste à créer un dataset équilibré avec classes “haricots” et “autres objets”, à normaliser et à préparer les images pour l’entraînement du modèle de classification.
	\item \textbf{Prétraitement pour la régression} : consiste à préparer uniquement les images de haricots, à normaliser les pixels et les labels (temps de cuisson), à appliquer les augmentations, puis à créer les splits train/validation/test.
\end{enumerate}

\subsection{Prétraitement des données pour la classification}

Le pipeline de classification consiste à préparer les images pour l'entraînement d'un modèle de type MobileNetV2 afin de déterminer si une image contient des haricots ou autre chose. Chaque étape est décrite ci-dessous avec le pseudo-code correspondant.


\begin{algorithm}[H]
\caption{Création des dossiers pour les données d'entraînement et de test}
Définir \texttt{base\_path} et chemins \texttt{train\_path}, \texttt{test\_path}\;
Créer dossiers \texttt{train\_path} et \texttt{test\_path} s'ils n'existent pas\;
\end{algorithm}

\begin{algorithm}[H]
\caption{Téléchargement et extraction du dataset COCO val2017}
Vérifier et télécharger \texttt{val2017.zip} si nécessaire\;
Extraire le contenu si dossier absent\;
Afficher message de disponibilité du dataset\;
\end{algorithm}

\begin{algorithm}[H]
\caption{Sélection et copie d'un sous-ensemble d'images dans les dossiers}
Lister images \texttt{.jpg}, prendre subset de 1000 images\;
Copier 800 images dans \texttt{train\_path}, 200 dans \texttt{test\_path}\;
Afficher confirmation\;
\end{algorithm}

\begin{algorithm}[H]
\caption{Chargement des chemins d'images et des labels de variétés}
Collecter chemins et labels depuis dossiers de classes\;
Indexer labels en tableau numérique\;
Afficher résumé des données chargées\;
\end{algorithm}

\begin{algorithm}[H]
\caption{Création d'un dataset TensorFlow optimisé}
Définir fonction \texttt{load\_image} pour lecture, redimensionnement, normalisation\;
Créer dataset \texttt{tf.data} avec mise en batch, mélange et préchargement\;
\end{algorithm}

\begin{algorithm}[H]
\caption{Chargement automatique des images avec Keras}
Utiliser \texttt{image\_dataset\_from\_directory} sur \texttt{train\_dir}\;
Paramétrer taille images, batch size et mélange\;
Afficher classes détectées\;
\end{algorithm}

\begin{algorithm}[H]
\caption{Comptage et visualisation de la distribution des images par classe}
Définir fonction de comptage des images par classe\;
Calculer et afficher la distribution (graphique histogramme)\;
\end{algorithm}

\begin{algorithm}[H]
\caption{Validation des images : intégrité et caractéristiques}
Lister tailles images valides, détecter images corrompues\;
Tracer histogrammes de dimensions et distributions colorimétriques\;
Calculer statistiques pixel (moyenne et écart-type) sur un batch\;
\end{algorithm}

\vspace{5mm}

\noindent\textbf{Description :} Ce processus couvre la préparation méthodique d'un dataset d'images pour classification, incluant gestion des dossiers, récupération des données, constitution des étiquettes, construction optimisée de pipelines TensorFlow, ainsi que analyses exploratoires de la distribution et qualité des images. Ces étapes assurent un cadre robuste et reproductible pour l'entraînement des modèles de machine learning.


La moyenne et l’écart-type des pixels sont utilisées pour normaliser les images. Cette normalisation standardise les données et facilite l’entraînement du modèle de classification.

\subsection{Prétraitement des données pour la régression}

Le prétraitement des données pour la régression suit un pipeline complet visant à préparer les images et les labels de temps de cuisson pour l’entraînement du modèle. Il comprend le chargement, la normalisation, l’augmentation, et la structuration des jeux de données.



\begin{algorithm}[H]
\caption{Préparation et augmentation du jeu de données d’images}
\Entrée{Fichier CSV avec chemins d’images et labels}
\Sortie{Jeux de données entraînement, validation et test augmentés et sauvegardés}

Charger CSV des chemins d’images et labels\;
Extraire chemins d’images et convertir labels en float\;
Définir transformations de base (redimensionnement, conversion tenseur)\;
Définir transformations d’augmentation (recadrage, flips, jitter, flou)\;

\ForEach{chemin d’image}{
    Ouvrir image, convertir en RGB\;
    Appliquer transformation de base\;
    Convertir en tableau numpy uint8\;
    Ajouter à liste images de base\;
}

Convertir listes images et labels en tableaux numpy\;
Normaliser labels (mise à l’échelle Min-Max)\;
Séparer données en ensembles entraînement, validation, test avec stratification\;

\ForEach{image dans ensemble entraînement}{
    Ajouter image originale et label\;
    \For{nombre d’augmentations}{
        Convertir image en PIL\;
        Appliquer transformations d’augmentation\;
        Convertir en numpy uint8\;
        Ajouter image augmentée et label\;
    }
}

Convertir listes augmentées en tableaux numpy\;
Enregistrer ensembles (entraînement, validation, test) dans fichiers HDF5 avec images et labels\;

\end{algorithm}

\vspace{5mm}

\noindent\textbf{Description :} Cet algorithme présente la préparation complète des données d’images pour un projet d’apprentissage profond incluant le chargement des chemins et labels, les transformations et augmentations d’images, la normalisation et la séparation du dataset, ainsi que la sauvegarde finale au format optimisé pour l’entraînement. Cette procédure garantit une base de données enrichie et stable pour des modèles robustes.

\section{Architectures de modèles}
\label{sec:modeles}

Conformément à la méthodologie :


\begin{itemize}
	\item  \textbf{MobileNetV2} pour la classification des images haricots (variétés)/autres
	\item \textbf{CNN personnalisés} (deux variantes) pour une extraction hiérarchique efficace.
	\item \textbf{MobileNetV2}, \textbf{EfficientNetB0}, \textbf{NASNetMobile} (apprentissage par transfert).
\end{itemize}

La tête de régression est composée d’une couche de sortie scalaire (\texttt{linear}).
La régularisation inclut un \texttt{dropout} de 0.3 et une pénalisation L2 (\(\lambda=10^{-4}\)).

\begin{table}[h!]
	\centering
	\caption{Hyperparamètres d’entraînement de régression retenus.}
	\label{tab:hyperparams}
	\begin{tabular}{l l}
		\toprule
		Paramètre                    & Valeur                                             \\ \midrule
		Optimiseur                   & Adam (\(\beta_1=0.9\), \(\beta_2=0.999\))          \\
		Taux d’apprentissage initial & \(10^{-4}\) + scheduler \texttt{ReduceLROnPlateau} \\
		Fonction de perte            & MSE                                                \\
		Métriques                    & MAE, RMSE, \(R^2\)                                 \\
		Batch size                   & 32                                                 \\
		Époques max                  & 100                                                \\
		Patience early stopping      & 5                                                  \\
		Dropout                      & 0.3                                                \\
		Régularisation L2            & \(10^{-4}\)                                        \\ \bottomrule
	\end{tabular}
\end{table}

\section{Stratégie d’entraînement}
\label{sec:entrainement}

\subsection{Classification avec MobileNetV2}
\section*{Création, compilation et affichage du modèle MobileNetV2 gelé}

\begin{algorithm}[H]
\caption{Entraînement et sauvegarde du modèle de classification}
\Entrée{Modèle compilé, ensembles \texttt{train\_ds} et \texttt{val\_ds}, nombre d'époques \texttt{EPOCHS}}
\Sortie{Modèle entraîné sauvegardé, historique d'entraînement}

Entraîner le modèle sur \texttt{train\_ds} et \texttt{val\_ds} pour \texttt{EPOCHS} époques\;
Sauvegarder le modèle entraîné\;
Extraire historique d’entraînement (accuracy, loss)\;
Tracer et afficher courbes d’accuracy et loss\;
\KwRet{historique}
\end{algorithm}

\vspace{8pt}

\begin{algorithm}[H]
\caption{Fonction d'entraînement pour modèles de régression avec early stopping}
\Entrée{Chemin jeu de données, nombre d’époques \texttt{EPOCHS}, taille batch, fonction \texttt{model\_builder}, patience}
\Sortie{Historique d’entraînement}

Initialiser meilleure validation MAE et compteur patience\;
Construire modèle via \texttt{model\_builder}\;
Initialiser dictionnaire historique\;
Charger jeu de données d’entraînement et calculer steps par époque\;

\For{$epoch \gets 1$ \KwTo \texttt{EPOCHS}}{
    Afficher numéro d’époque\;
    Créer générateur de batchs\;
    Entraîner modèle sur une époque complète\;
    Récupérer loss et MAE d’entraînement\;
    Évaluer sur validation : val\_loss et val\_mae\;
    Enregistrer métriques dans historique\;
    Afficher résumé résultats\;
    \If{val\_mae s’améliore}{
        Sauvegarder modèle\;
        Réinitialiser compteur patience\;
    }
    \Else{
        Incrémenter compteur patience\;
        \If{compteur atteint patience maximale}{
            Arrêter entraînement prématurément\;
        }
    }
    Libérer mémoire générateur\;
}

Afficher fin d'entraînement\;
Fermer loader de données\;
\KwRet{historique}
\end{algorithm}

\vspace{8pt}

\noindent\textbf{Description :} Ces algorithmes détaillent les procédures d'entraînement supervisé pour les modèles de classification et régression. Le suivi des métriques pendant l'entraînement, ainsi que l'utilisation d'un mécanisme d'early stopping pour la régression, permettent d'améliorer la généralisation en évitant le surapprentissage. La sauvegarde périodique du modèle assure la conservation des meilleurs poids selon la performance de validation.

\section*{Export et optimisation TinyML}

\subsection*{Quantification complète INT8 pour la classification}


\begin{algorithm}[H]
\caption{Conversion du modèle classification MobileNetV2 en TFLite quantifié INT8}
\Entrée{Modèle TensorFlow SavedModel, chemin de sauvegarde TFLite}
\Sortie{Modèle TFLite quantifié INT8 sauvegardé}

Définir chemin de sauvegarde TFLite\;
Charger modèle TensorFlow SavedModel\;
Initialiser convertisseur TFLite\;
Activer optimisations par défaut\;
Définir dataset représentatif (exemple : 100 images du jeu de test)\;
Configurer quantification complète INT8 : \\
\hspace{5mm} - Inputs : uint8 \\
\hspace{5mm} - Outputs : uint8 \\
\hspace{5mm} - Calibration avec dataset représentatif\;
Convertir modèle en TFLite\;
Sauvegarder modèle TFLite quantifié\;
Afficher message de succès de la conversion\;
\end{algorithm}

\vspace{5mm}

\noindent\textbf{Description :} Cette conversion INT8 optimise la taille mémoire et la vitesse d'exécution sur dispositifs embarqués tout en conservant une bonne précision. La calibration avec un dataset représentatif est cruciale pour assurer une quantification efficace et fidèle du modèle.

\bigskip

\subsection*{Conversion TensorFlow Lite pour la régression (float16)}

\begin{algorithm}[H]
\caption{Conversion du modèle régression en TFLite float16}
\Entrée{Modèle TensorFlow SavedModel, chemin de sauvegarde TFLite}
\Sortie{Modèle TFLite float16 sauvegardé}

Importer TensorFlow version 2.13\;
Charger modèle SavedModel de régression\;
Initialiser convertisseur TFLite\;
Activer optimisations par défaut\;
Définir type de données cible : float16 (réduction mémoire d'environ 50\%)\;
Convertir modèle en format TFLite\;
Sauvegarder fichier binaire TFLite\;
Afficher message de succès\;
\end{algorithm}

\vspace{5mm}

\noindent\textbf{Description :} Cette conversion en float16 permet de diminuer significativement la taille du modèle de régression tout en préservant une précision élevée, ce qui est particulièrement adapté pour TinyML sur dispositifs embarqués à ressources limitées.

\section{Déploiement Android}
\label{sec:deploiement_android}

\subsection{Cible et outils}
Le déploiement a été effectué sur un \textbf{Samsung Galaxy Note 9} (Android 10, 6 Go RAM, 128 Go stockage) via une application développée avec :
\begin{itemize}
    \item \textbf{Android Studio} Narwhal (2025.1.2), \textbf{SDK} Android 36.
    \item Compatibilité descendante : \texttt{minSdkVersion=26} (Android 8.0).
    \item \textbf{Langage} : Kotlin.
    \item \textbf{Runtime ML} : \texttt{TensorFlow Lite Interpreter} v2.13.
\end{itemize}

\subsection{Architecture logicielle de l’application}
L’application mobile repose sur une architecture modulaire :
\begin{itemize}
    \item \textbf{Interface utilisateur (UI)} : importation des photos de haricots et affichage des résultats.
    \item \textbf{Module de classification} : MobileNetV2 quantifié INT8, détermine si l’image contient des haricots.
    \item \textbf{Module de régression} : CNN personnalisé (TFLite float16), estime le temps de cuisson.
    \item \textbf{Gestionnaire d’inférence} : orchestre les prétraitements, les appels aux modèles et la dénormalisation.
    \item \textbf{Module résultats} : restitution de la variété détectée, du temps de cuisson estimé, de la latence et des métriques (MAE, RMSE, accuracy).
\end{itemize}

\subsection{Intégration et inférence}
\begin{algorithm}[H]
    \caption{Pipeline de prédiction du temps de cuisson des haricots}
    \Image{Image de haricot sous forme de bitmap}
    \Temps{Temps de cuisson estimé et variété détectée}

    \SetKwFunction{FMain}{RunPrediction}
    \SetKwFunction{FClassify}{runClassification}
    \SetKwFunction{FRegress}{runRegression}

    \SetKwProg{Fn}{Fonction}{ :}{}
    \Fn{\FMain{$context$, $bitmap$}}{
        Mettre à jour l'image affichée avec $bitmap$\;
        Afficher ``Analyse en cours...''\;
        Convertir $bitmap$ en format ARGB\_8888 si nécessaire\;
        \tcp{Étape 1 : Classification}
        $(classePrédite, score) \gets$ \FClassify{$context$, $bitmap$}\;
        \eIf{$classePrédite =$ ``autre''}{
            Afficher message d'erreur indiquant image non reconnue comme haricot\;
            Afficher métriques classification (Précision, Recall, F1-score)\;
        }{
            \tcp{Étape 2 : Régression}
            Démarrer chronomètre\;
            $temps \gets$ \FRegress{$context$, $bitmap$}\;
            Arrêter chronomètre\;
            Afficher variété détectée : $classePrédite$\;
            Afficher temps de cuisson estimé : $temps$ minutes\;
            Afficher latence de prédiction\;
            Afficher métriques régression (RMSE, MAE) et classification\;
        }
        \KwRet{}
    }

    \SetKwProg{Fn}{Fonction}{ :}{}
    \Fn{\FClassify{$context$, $bitmap$}}{
        Redimensionner $bitmap$ en $224 \times 224$\;
        Convertir pixels en \texttt{ByteBuffer} UINT8 (sans normalisation)\;
        Charger modèle TFLite quantifié int8 ``bean\_classifier.tflite''\;
        Exécuter inférence pour obtenir sortie UINT8\;
        Trouver indice de la classe ayant le score maximum\;
        \KwRet{(classe correspondante, indice)}
    }

    \SetKwProg{Fn}{Fonction}{ :}{}
    \Fn{\FRegress{$context$, $bitmap$}}{
        Redimensionner $bitmap$ en $224 \times 224$\;
        Convertir pixels en tableau float normalisé en $[0,1]$\;
        Charger modèle TFLite float16 ``bean\_regressor.tflite''\;
        Exécuter inférence pour obtenir sortie float32\;
        Dénormaliser la sortie pour obtenir temps cuisson :
        \[
            \text{temps} = \text{valeurNormalise} \times (410 - 51) + 51
        \]
        \KwRet{temps}
    }

    \SetKwProg{Fn}{Fonction}{ :}{}
    \Fn{Réinitialiser}{
        Mettre à null \texttt{imageBitmap} et \texttt{predictionResult}\;
    }
\end{algorithm}


% \subsection{Limites rencontrées}
% Plusieurs limites ont été observées lors du déploiement :
% \begin{itemize}
%     \item \textbf{Latence} : bien que le CNN personnalisé soit rapide ($\approx$160 ms), MobileNetV2 présente une latence perceptible ($\approx$467 ms).
%     \item \textbf{Consommation mémoire} : les modèles pré-entraînés (EfficientNetB0, NASNetMobile) sont trop lourds pour des smartphones anciens.
%     \item \textbf{Robustesse aux conditions réelles} : perte de précision avec des photos floues, mal éclairées ou prises sous un angle extrême.
%     \item \textbf{Compatibilité} : l’utilisation de TensorFlow Lite impose Android ≥ 8.0, excluant certains appareils.
% \end{itemize}

% \subsection{Résumé}
% Le déploiement Android valide la faisabilité d’un système embarqué de prédiction du temps de cuisson des haricots. Les modèles quantifiés offrent un bon compromis entre précision et rapidité, avec une préférence pour le CNN personnalisé. L’intégration ouvre la voie à des applications pratiques dans un contexte domestique ou agroalimentaire.


\section{Mesures et artefacts à produire}
\label{sec:mesures_artefacts}

Cette section ne présente \emph{pas} de résultats chiffrés (qui seront rapportés au Chapitre Résultats), mais liste les artefacts générés.

\begin{table}[h!]
	\centering
	\caption{Synthèse des modèles déployés.}
	\begin{tabular}{l l l l}
		\toprule
		Modèle                       & Taille (Mo) & Latence Android (ms) & Métriques     \\ \midrule
		CNN personnalisé 1           & 0.9         & 160                  & 26 (min) RMSE \\
		MobileNetV2 (classification) & 2.5         & 467                  & 97\% accuracy \\ \bottomrule
	\end{tabular}
\end{table}

\section{Résumé du chapitre}

Ce chapitre a présenté :

\begin{itemize}
	\item Le \textbf{prétraitement des images} pour la classification et la régression.
	\item La \textbf{création et entraînement} des modèles CNN et d’apprentissage par transfert.
	\item L’\textbf{export TFLite} optimisé pour TinyML et l’intégration Android.
	\item La \textbf{structure de l’application mobile} et le workflow d’inférence.
\end{itemize}

La prochaine étape consiste à analyser les \textbf{performances quantitatives} des modèles et à produire les \textbf{visualisations et métriques finales} présentées au Chapitre~\ref{chap:resultats_discussion}.
